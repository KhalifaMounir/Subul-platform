version: '3.8'

services:
  postgres:
    container_name: db_postgres
    image: pgvector/pgvector:pg16
    env_file:
      - .env
    ports:
      - "5434:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  backend:
    build:
      context: .
      dockerfile: backend/Dockerfile
    ports:
      - "5000:5000"
    env_file:
      - .env
    depends_on:
      - postgres

  frontend:
    build:
      context: ./frontend
    ports:
      - "3000:3000"
    depends_on:
      - backend

  zookeeper:
    image: confluentinc/cp-zookeeper:7.2.1
    container_name: job_zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"

  kafka:
    image: confluentinc/cp-kafka:7.2.1
    container_name: job_kafka
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    ports:
      - "9092:9092"

  job_scraper:
    build:
      context: .
      dockerfile: jobsearchsubul/Dockerfile
    container_name: job_scraper
    working_dir: /app
    depends_on:
      - kafka
    volumes:
      - ./jobsearchsubul:/app/jobsearchsubul
      - ./backend:/app/backend

  job_consumer:
    build:
      context: .
      dockerfile: jobsearchsubul/Dockerfile
    container_name: job_consumer
    working_dir: /app
    command: ["python3", "jobsearchsubul/tools/consumer.py"]
    depends_on:
      - kafka
      - postgres
    env_file:
      - .env
    volumes:
      - ./jobsearchsubul:/app/jobsearchsubul
      - ./backend:/app/backend

  airflow-init:
    build:
      context: .
      dockerfile: jobsearchsubul/dags/Dockerfile
    image: apache/airflow:2.9.2-python3.8
    container_name: airflow-init
    command: bash -c "airflow db init && airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com"
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=${AIRFLOW__DATABASE__SQL_ALCHEMY_CONN}
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__CORE__FERNET_KEY=aZ34f8xPjP1n4d8zYvT2aHlG9Q8IzKzKPTmX1AvMKr4=
      - AIRFLOW__WEBSERVER__SECRET_KEY=aZ34f8xPjP1n4d8zYvT2aHlG9Q8IzKzKPTmX1AvMKr4=
      - ./logs:/opt/airflow/logs
    volumes:
      - ./jobsearchsubul/dags:/opt/airflow/dags
      - ./jobsearchsubul/tools:/opt/airflow/scripts/tools
    depends_on:
      - postgres
    env_file:
      - .env

  airflow-webserver:
    build:
      context: .
      dockerfile: jobsearchsubul/dags/Dockerfile
    image: apache/airflow:2.9.2-python3.8
    container_name: airflow-webserver
    command: webserver
    ports:
      - "8080:8080"
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=${AIRFLOW__DATABASE__SQL_ALCHEMY_CONN}
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__CORE__FERNET_KEY=aZ34f8xPjP1n4d8zYvT2aHlG9Q8IzKzKPTmX1AvMKr4=
      - AIRFLOW__WEBSERVER__SECRET_KEY=aZ34f8xPjP1n4d8zYvT2aHlG9Q8IzKzKPTmX1AvMKr4=
      - ./logs:/opt/airflow/logs

    volumes:
      - ./jobsearchsubul/dags:/opt/airflow/dags
      - ./jobsearchsubul/tools:/opt/airflow/scripts/tools
    depends_on:
      - airflow-init
    env_file:
      - .env

  airflow-scheduler:
    build:
      context: .
      dockerfile: jobsearchsubul/dags/Dockerfile
    image: apache/airflow:2.9.2-python3.8
    container_name: airflow-scheduler
    command: scheduler
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=${AIRFLOW__DATABASE__SQL_ALCHEMY_CONN}
      - AIRFLOW__CORE__FERNET_KEY=aZ34f8xPjP1n4d8zYvT2aHlG9Q8IzKzKPTmX1AvMKr4=
      - AIRFLOW__WEBSERVER__SECRET_KEY=aZ34f8xPjP1n4d8zYvT2aHlG9Q8IzKzKPTmX1AvMKr4=

    volumes:
      - ./jobsearchsubul/dags:/opt/airflow/dags
      - ./jobsearchsubul/tools:/opt/airflow/scripts/tools
      - ./logs:/opt/airflow/logs
    depends_on:
      - airflow-init
    env_file:
      - .env

volumes:
  postgres_data:
